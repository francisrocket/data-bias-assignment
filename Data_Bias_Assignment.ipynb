{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8098727d",
   "metadata": {},
   "source": [
    "### Data Bias Assignment\n",
    "### Francis Tang fjt378"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d1a78",
   "metadata": {},
   "source": [
    "### Installing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ea61908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (2.83.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-python-client) (2.17.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-python-client) (2.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.59.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.27.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (4.22.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695e984",
   "metadata": {},
   "source": [
    "### Testing Perspective API for Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b26e59b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of scores from the Perspective API for toxicity of comments which were human-labeled as toxic: [0.718943, 0.8778702, 0.6491204, 0.45703048, 0.7510937, 0.85850734, 0.8115627, 0.5721988, 0.8696708, 0.47323486, 0.3561489, 0.8988238]\n",
      "List of scores from the Perspective API for toxicity of comments which were human-labeled as nontoxic: [0.016210219, 0.4014846, 0.43230394, 0.050821137, 0.027088705, 0.025910228, 0.07212844, 0.10089093, 0.3389984, 0.10522962, 0.4574824, 0.014011159]\n",
      "\n",
      "Minimum and Maximum Toxicity Score of Sample Toxic Comments: 0.3561489, 0.8988238\n",
      "Minimum and Maximum Toxicity Score of Sample Non-Toxic Comments: 0.014011159, 0.4574824\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "import json\n",
    "\n",
    "API_KEY = 'AIzaSyBbe-aYKJT0itrpGAmjsrIxhDX9iDxb1G0'\n",
    "\n",
    "client = discovery.build(\n",
    "  \"commentanalyzer\",\n",
    "  \"v1alpha1\",\n",
    "  developerKey=API_KEY,\n",
    "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "  static_discovery=False,\n",
    ")\n",
    "\n",
    "analyze_request1 = {\n",
    "  'comment': { 'text': ' Arabs are committing genocide in Iraq but no protests in Europe   May Europe also burn in hell' },\n",
    "  'requestedAttributes': {'TOXICITY': {}}\n",
    "}\n",
    "\n",
    "# 12 (a dozen) comments which are labeled toxic\n",
    "toxic_comments = [\" Arabs are committing genocide in Iraq but no protests in Europe   May Europe also burn in hell\",\n",
    "                 \"No he is an arrogant self serving immature idiot Get it right\",\n",
    "                 \"Eek but shes cute in an earthy kind of way Cant sing for shit though Thanks for giving me an unhappy memory\",\n",
    "                 \"Well it sucks to have a university to be nicknameless And its the first time in NCAA history that it has happened \",\n",
    "                 \" Argh   Some random idiot deleted the whole Japan article \",\n",
    "                 \"we hate america and we are going to bomb the shit out of there cities Quezas will rain\",\n",
    "                 \"Being drunk made Gibson say what he really believes The little freak is a Nazi like his father and I hope he dies of lung cancer Soon\",\n",
    "                 \"How dare you vandalize that page about the HMS Beagle Dont vandalize again demon\",\n",
    "                 \" Bold textYOU SUCK     U SUCK HANNAH MONTANA\",\n",
    "                 \"Moi Ego I am mortified that you could say such a thing  poor old Mona I always thiught she was a miserable looking woman  probably hormonal\",\n",
    "                 \"  So on the tenth anniversary of 911 New York Times columnist Paul Krugman delivered the odious piece of dribble ever on the attack  well at least since the last time he wrote about it The headline is quote The Years of Shame end quote And no its not directed at radical Islam Instead he targets America and the quote fake heroes Krugman claims that the atrocity has been hijacked The sick word given that hes not actually talking about the real hijackers who killed some 3000 Americans No hes referring to people like George Bush and Rudy Giuliani who he thinks capitalized on the horrible crimes But the worst part at the end of this column the creep writes Im not going to allow comments on the post for obvious reasons That obvious reason hes a coward I mean why else would you ban responses Hes like a 10yearold boy crankcalling all of us only to hang up even before he hears a response hearing his shame for his own wickedness Now I watch the memorial services and I feel sorrow for the families whose grief never really ends But since Im lousy at emotional reflection I usually avoid it But at least I can summarize what many feel today in nine words go to hell Paul Krugman you bearded bitter buffoon\",\n",
    "                 \"Simple You are stupid\"]\n",
    "\n",
    "# 12 (a dozen) comments which are nonlabeled toxic\n",
    "nontoxic_comments = [\"Thank you for understanding I think very highly of you and would not revert without discussion\",\n",
    "                    \"Dear god this site is horrible\",\n",
    "                    \" Somebody will invariably try to add Religion  Really  You mean the way people have invariably kept adding Religion to the Samuel Beckett infobox  And why do you bother bringing up the longdead completely nonexistent Influences issue  Youre just flailing making up crap on the fly   For comparison the only explicit acknowledgement in the entire Amos Oz article that he is personally Jewish is in the categories     \",\n",
    "                    \"  It says it right there that it IS a type The Type of institution is needed in this case because there are three levels of SUNY schools  University Centers and Doctoral Granting Institutions  State Colleges  Community Colleges  It is needed in this case to clarify that UB is a SUNY Center It says it even in Binghamton University University at Albany State University of New York and Stony Brook University Stop trying to say its not because I am totally right in this case\",\n",
    "                    \"   Before adding a new product to the list make sure its relevant   Before adding a new product to the list make sure it has a wikipedia entry already proving its relevance and giving the reader the possibility to read more about it  Otherwise it could be subject to deletion See this articles revision history\",\n",
    "                    \"this other one from 1897\",\n",
    "                    \" Reason for banning throwing   This article needs a section on why throwing is banned At the moment to a noncricket fan it seems kind of arbitrary\",\n",
    "                    \"blocked from editing Wikipedia   \",\n",
    "                    \"Please stop If you continue to vandalize Wikipedia as you did to Homosexuality you will be blocked from editing\",\n",
    "                    \"RedSlash cut it short If you have sources stating the RoK is sovereign post them Otherwise please aknowledge WP is not the place to make OR\",\n",
    "                    \"            Jews are not a race because you can only get it from your mother Your own mention of Ethiopian Jews not testing            as Jews proves it is not as well as the fact that we accept converts\",\n",
    "                    \"If Ollie or others think that one list of the oldest people we know about is too long the easy answer is to raise the cutoff age 110 is purely a round number and a full 12 years shorter then the record We can make it the top 1000 or top 500 or everyone above 115  tell us what the maximum list size is and we can set a threshold\"]\n",
    "\n",
    "toxic_comment_scores = []\n",
    "nontoxic_comment_scores = []\n",
    "\n",
    "# loop through the list of comments calling the API to get its toxicity score and appending the scores to a list\n",
    "for c in toxic_comments:\n",
    "    analyze_request = {'comment': { 'text': c },'requestedAttributes': {'TOXICITY': {}}}\n",
    "    response = client.comments().analyze(body=analyze_request).execute()\n",
    "    #print(json.dumps(response, indent=2))\n",
    "    score = response[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"]\n",
    "    toxic_comment_scores.append(score)\n",
    "    \n",
    "for c in nontoxic_comments:\n",
    "    analyze_request = {'comment': { 'text': c },'requestedAttributes': {'TOXICITY': {}}}\n",
    "    response = client.comments().analyze(body=analyze_request).execute()\n",
    "    #print(json.dumps(response, indent=2))\n",
    "    score = response[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"]\n",
    "    nontoxic_comment_scores.append(score)\n",
    "\n",
    "# print out the scores that the Perspective API gave for the comments\n",
    "print(f\"List of scores from the Perspective API for toxicity of comments which were human-labeled as toxic: {toxic_comment_scores}\")\n",
    "print(f\"List of scores from the Perspective API for toxicity of comments which were human-labeled as nontoxic: {nontoxic_comment_scores}\")\n",
    "print()\n",
    "\n",
    "# prints out basic statistics about the toxicity scores of the two groups (minimum and maximum for the toxic group and nontoxic group)\n",
    "print(f\"Minimum and Maximum Toxicity Score of Sample Toxic Comments: {min(toxic_comment_scores)}, {max(toxic_comment_scores)}\")\n",
    "\n",
    "print(f\"Minimum and Maximum Toxicity Score of Sample Non-Toxic Comments: {min(nontoxic_comment_scores)}, {max(nontoxic_comment_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f48082",
   "metadata": {},
   "source": [
    "### Combining data and converting to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f42e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data to csv\n",
    "import pandas as pd\n",
    "data_tuples = list(zip(toxic_comments + nontoxic_comments, toxic_comment_scores + nontoxic_comment_scores))\n",
    "data_df = pd.DataFrame(data_tuples, columns=['Text','Toxicity Score'])\n",
    "\n",
    "data_df.to_csv(\"conversations_toxicity_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c471a",
   "metadata": {},
   "source": [
    "### Analysis: Hypothesis\n",
    "\n",
    "My hypothesis is that the Perspective API will make more mistakes in assessing the toxicity of a long piece of text compared to a short piece of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f984354",
   "metadata": {},
   "source": [
    "### Analysis: Threshold\n",
    "\n",
    "From the results returned by the Perspective API, I have determined that an appropriate threshold for toxicity score to determine a comment to be toxic as 0.45, or 45% certainty. With my hypothesis being that shorter text will result in more mistakes than longer text, I will examine the comments which were incorrectly assessed and check their lengths to see if there is indeed any correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65527b77",
   "metadata": {},
   "source": [
    "### Testing hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bcda5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of toxic comment: 179\n",
      "Average length of comment incorrectly labeled toxic: 1208\n",
      "\n",
      "Average length of nontoxic comment: 192\n",
      "Average length of comment incorrectly labeled nontoxic: 203\n"
     ]
    }
   ],
   "source": [
    "# getting the incorrectly labeled toxic text's data, score, and length\n",
    "incorrectly_labeled_toxic = [\"  So on the tenth anniversary of 911 New York Times columnist Paul Krugman delivered the odious piece of dribble ever on the attack  well at least since the last time he wrote about it The headline is quote The Years of Shame end quote And no its not directed at radical Islam Instead he targets America and the quote fake heroes Krugman claims that the atrocity has been hijacked The sick word given that hes not actually talking about the real hijackers who killed some 3000 Americans No hes referring to people like George Bush and Rudy Giuliani who he thinks capitalized on the horrible crimes But the worst part at the end of this column the creep writes Im not going to allow comments on the post for obvious reasons That obvious reason hes a coward I mean why else would you ban responses Hes like a 10yearold boy crankcalling all of us only to hang up even before he hears a response hearing his shame for his own wickedness Now I watch the memorial services and I feel sorrow for the families whose grief never really ends But since Im lousy at emotional reflection I usually avoid it But at least I can summarize what many feel today in nine words go to hell Paul Krugman you bearded bitter buffoon\"]\n",
    "incorrectly_labeled_toxic_scores = [0.3561489]\n",
    "avg_len_incorrectly_labeled_toxic = len(incorrectly_labeled_toxic[0])\n",
    "\n",
    "# getting the avg length of toxic comments to compare with the length of the incorrectly labeled one\n",
    "avg_len_toxic = 0\n",
    "\n",
    "for c in toxic_comments:\n",
    "    avg_len_toxic += len(c)\n",
    "\n",
    "avg_len_toxic /= 12\n",
    "\n",
    "# getting the incorrectly labeled nontoxic text's data, score, and length\n",
    "incorrectly_labeled_nontoxic = [\"            Jews are not a race because you can only get it from your mother Your own mention of Ethiopian Jews not testing            as Jews proves it is not as well as the fact that we accept converts\"]\n",
    "incorrectly_labeled_nontoxic_scores = [0.4574824]\n",
    "avg_len_incorrectly_labeled_nontoxic = len(incorrectly_labeled_nontoxic[0])\n",
    "\n",
    "# getting the avg length of nontoxic comments to compare with the length of the incorrectly labeled one\n",
    "avg_len_nontoxic = 0\n",
    "\n",
    "for c in nontoxic_comments:\n",
    "    avg_len_nontoxic += len(c)\n",
    "\n",
    "avg_len_nontoxic /= 12\n",
    "\n",
    "print(f\"Average length of toxic comment: {round(avg_len_toxic)}\")\n",
    "print(f\"Average length of comment incorrectly labeled toxic: {avg_len_incorrectly_labeled_toxic}\")\n",
    "print()\n",
    "print(f\"Average length of nontoxic comment: {round(avg_len_nontoxic)}\")\n",
    "print(f\"Average length of comment incorrectly labeled nontoxic: {avg_len_incorrectly_labeled_nontoxic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92331ea6",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "As we can wee, the average length of a toxic comment is 179 characters, and the comment which was incorrectly labeled as toxic had a much greater length of 1208. This supports our hypothesis that the Perspective API would be more likely to make mistakes on assessing the toxicity of a long piece of text rather than make a mistake in assessing the toxicity of a short piece of text. Additionally, we also looked at the average length of a nontoxic comment, which was 192, and the comment which was incorrectly labeled as nontoxic had length of 203, similar in length but about 5% longer. This also supports our hypothesis that the Perspective API would be more likely to make mistakes on assessing the toxicity of a long piece of text rather than make a mistake in assessing the toxicity of a short piece of text.\n",
    "\n",
    "A low sample size of 12 impacted our results by giving us few data points to work with. Mistakes in the first place seem to be relatively rare, as shown by finding only 1 mistake among the 12 data points and 2 among the 24 total data points. We can still begin to draw conclusions, but they should by no means be conclusive due to the low sample size. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc5268",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f09acd",
   "metadata": {},
   "source": [
    "Overall, I find this small project to be a very positive experience from which I learned a lot. I learned from the ground up how to use an API from Google Cloud and incorporate it in a project done from scratch. This involves getting the API, enabling it, figuring out how to use it (by getting an API key), and incorporating it into my code so that I can call it to perform it's various functions, in this case being a machine learning model which can score texts for toxicity. \n",
    "\n",
    "A surprising result I got was that the API does in fact seem more accurate with short texts than long texts, and I had initially thought that there are reasons to support either side of that argument. Short texts could be more innacurate because there might be less context that the API can derive in order to make it's decision, and it doesn't have many total words to work with. On the other hand, long texts give the API plenty of material to work with, but as we saw in our tests, long text is still able to \"trick\" the API into making an inaccuracy by potentially including lots of filler and carefully incorporating the insults and toxicity in more subtle ways. This could suggest that the model may draw its conclusions a bit too quickly, and may benefit from training with data that contains different punctionation types that elongate the sentence. \n",
    "\n",
    "To summarize, my hypothesis was that I thought the model would be more accurate with shorter text, and the bias that my tests suggested is in fact a bias towards shorter text, seeing that it was more accurate with shorter text than longer text. My theory for this bias is that there was less training data that included long text with punctations and  rarer grammatical forms, and thus the model became less accurate on this type of data and more accurate with short text data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
