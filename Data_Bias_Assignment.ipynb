{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29123dba",
   "metadata": {},
   "source": [
    "### Data Bias Assignment\n",
    "### Francis Tang fjt378"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d0227",
   "metadata": {},
   "source": [
    "### Installing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e2b010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (2.83.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-python-client) (2.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-python-client) (2.17.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.59.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.27.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (4.22.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/francistang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ae9e9",
   "metadata": {},
   "source": [
    "### Testing Perspective API for Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28552cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of scores from the Perspective API for toxicity of comments which were human-labeled as toxic: [0.718943, 0.8778702, 0.6491204, 0.45703048, 0.7510937, 0.85850734, 0.8115627, 0.5721988, 0.8696708, 0.47323486, 0.3561489, 0.8988238]\n",
      "List of scores from the Perspective API for toxicity of comments which were human-labeled as nontoxic: [0.016210219, 0.4014846, 0.43230394, 0.050821137, 0.027088705, 0.025910228, 0.07212844, 0.10089093, 0.3389984, 0.10522962, 0.4574824, 0.014011159]\n",
      "\n",
      "Minimum and Maximum Toxicity Score of Sample Toxic Comments: 0.3561489, 0.8988238\n",
      "Minimum and Maximum Toxicity Score of Sample Non-Toxic Comments: 0.014011159, 0.4574824\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "import json\n",
    "\n",
    "API_KEY = 'AIzaSyBbe-aYKJT0itrpGAmjsrIxhDX9iDxb1G0'\n",
    "\n",
    "client = discovery.build(\n",
    "  \"commentanalyzer\",\n",
    "  \"v1alpha1\",\n",
    "  developerKey=API_KEY,\n",
    "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "  static_discovery=False,\n",
    ")\n",
    "\n",
    "analyze_request1 = {\n",
    "  'comment': { 'text': ' Arabs are committing genocide in Iraq but no protests in Europe   May Europe also burn in hell' },\n",
    "  'requestedAttributes': {'TOXICITY': {}}\n",
    "}\n",
    "\n",
    "# 12 (a dozen) comments which are labeled toxic\n",
    "toxic_comments = [\" Arabs are committing genocide in Iraq but no protests in Europe   May Europe also burn in hell\",\n",
    "                 \"No he is an arrogant self serving immature idiot Get it right\",\n",
    "                 \"Eek but shes cute in an earthy kind of way Cant sing for shit though Thanks for giving me an unhappy memory\",\n",
    "                 \"Well it sucks to have a university to be nicknameless And its the first time in NCAA history that it has happened \",\n",
    "                 \" Argh   Some random idiot deleted the whole Japan article \",\n",
    "                 \"we hate america and we are going to bomb the shit out of there cities Quezas will rain\",\n",
    "                 \"Being drunk made Gibson say what he really believes The little freak is a Nazi like his father and I hope he dies of lung cancer Soon\",\n",
    "                 \"How dare you vandalize that page about the HMS Beagle Dont vandalize again demon\",\n",
    "                 \" Bold textYOU SUCK     U SUCK HANNAH MONTANA\",\n",
    "                 \"Moi Ego I am mortified that you could say such a thing  poor old Mona I always thiught she was a miserable looking woman  probably hormonal\",\n",
    "                 \"  So on the tenth anniversary of 911 New York Times columnist Paul Krugman delivered the odious piece of dribble ever on the attack  well at least since the last time he wrote about it The headline is quote The Years of Shame end quote And no its not directed at radical Islam Instead he targets America and the quote fake heroes Krugman claims that the atrocity has been hijacked The sick word given that hes not actually talking about the real hijackers who killed some 3000 Americans No hes referring to people like George Bush and Rudy Giuliani who he thinks capitalized on the horrible crimes But the worst part at the end of this column the creep writes Im not going to allow comments on the post for obvious reasons That obvious reason hes a coward I mean why else would you ban responses Hes like a 10yearold boy crankcalling all of us only to hang up even before he hears a response hearing his shame for his own wickedness Now I watch the memorial services and I feel sorrow for the families whose grief never really ends But since Im lousy at emotional reflection I usually avoid it But at least I can summarize what many feel today in nine words go to hell Paul Krugman you bearded bitter buffoon\",\n",
    "                 \"Simple You are stupid\"]\n",
    "\n",
    "# 12 (a dozen) comments which are nonlabeled toxic\n",
    "nontoxic_comments = [\"Thank you for understanding I think very highly of you and would not revert without discussion\",\n",
    "                    \"Dear god this site is horrible\",\n",
    "                    \" Somebody will invariably try to add Religion  Really  You mean the way people have invariably kept adding Religion to the Samuel Beckett infobox  And why do you bother bringing up the longdead completely nonexistent Influences issue  Youre just flailing making up crap on the fly   For comparison the only explicit acknowledgement in the entire Amos Oz article that he is personally Jewish is in the categories     \",\n",
    "                    \"  It says it right there that it IS a type The Type of institution is needed in this case because there are three levels of SUNY schools  University Centers and Doctoral Granting Institutions  State Colleges  Community Colleges  It is needed in this case to clarify that UB is a SUNY Center It says it even in Binghamton University University at Albany State University of New York and Stony Brook University Stop trying to say its not because I am totally right in this case\",\n",
    "                    \"   Before adding a new product to the list make sure its relevant   Before adding a new product to the list make sure it has a wikipedia entry already proving its relevance and giving the reader the possibility to read more about it  Otherwise it could be subject to deletion See this articles revision history\",\n",
    "                    \"this other one from 1897\",\n",
    "                    \" Reason for banning throwing   This article needs a section on why throwing is banned At the moment to a noncricket fan it seems kind of arbitrary\",\n",
    "                    \"blocked from editing Wikipedia   \",\n",
    "                    \"Please stop If you continue to vandalize Wikipedia as you did to Homosexuality you will be blocked from editing\",\n",
    "                    \"RedSlash cut it short If you have sources stating the RoK is sovereign post them Otherwise please aknowledge WP is not the place to make OR\",\n",
    "                    \"            Jews are not a race because you can only get it from your mother Your own mention of Ethiopian Jews not testing            as Jews proves it is not as well as the fact that we accept converts\",\n",
    "                    \"If Ollie or others think that one list of the oldest people we know about is too long the easy answer is to raise the cutoff age 110 is purely a round number and a full 12 years shorter then the record We can make it the top 1000 or top 500 or everyone above 115  tell us what the maximum list size is and we can set a threshold\"]\n",
    "\n",
    "toxic_comment_scores = []\n",
    "nontoxic_comment_scores = []\n",
    "\n",
    "# loop through the list of comments calling the API to get its toxicity score and appending the scores to a list\n",
    "for c in toxic_comments:\n",
    "    analyze_request = {'comment': { 'text': c },'requestedAttributes': {'TOXICITY': {}}}\n",
    "    response = client.comments().analyze(body=analyze_request).execute()\n",
    "    #print(json.dumps(response, indent=2))\n",
    "    score = response[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"]\n",
    "    toxic_comment_scores.append(score)\n",
    "    \n",
    "for c in nontoxic_comments:\n",
    "    analyze_request = {'comment': { 'text': c },'requestedAttributes': {'TOXICITY': {}}}\n",
    "    response = client.comments().analyze(body=analyze_request).execute()\n",
    "    #print(json.dumps(response, indent=2))\n",
    "    score = response[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"]\n",
    "    nontoxic_comment_scores.append(score)\n",
    "\n",
    "# print out the scores that the Perspective API gave for the comments\n",
    "print(f\"List of scores from the Perspective API for toxicity of comments which were human-labeled as toxic: {toxic_comment_scores}\")\n",
    "print(f\"List of scores from the Perspective API for toxicity of comments which were human-labeled as nontoxic: {nontoxic_comment_scores}\")\n",
    "print()\n",
    "\n",
    "# prints out basic statistics about the toxicity scores of the two groups (minimum and maximum for the toxic group and nontoxic group)\n",
    "print(f\"Minimum and Maximum Toxicity Score of Sample Toxic Comments: {min(toxic_comment_scores)}, {max(toxic_comment_scores)}\")\n",
    "\n",
    "print(f\"Minimum and Maximum Toxicity Score of Sample Non-Toxic Comments: {min(nontoxic_comment_scores)}, {max(nontoxic_comment_scores)}\")\n",
    "\n",
    "#\n",
    "# 12 (a dozen) comments which are expected to be toxic but were initially labeled nontoxic\n",
    "#expected_toxic_comments = [\"I WILL BURN YOU TO HELL IF YOU REVOKE MY TALK PAGE ACCESS\",\n",
    "                          #\"WHAT THE HELL    Justin\",\n",
    "                          #\" hello   you are an T0TL D0UCH3 BG\",\n",
    "                          #\" Freeway 2   Definitely one of the most difficult movies to watch  Necrophilia crack guns lesbians a crazy cult bondage bulimia prostitution you name it this movies got it  Oddly compelling sometimes unintentionally funny and altogether disturbing\",\n",
    "                          #\"666 the devil will get you all   \",\n",
    "                          #\"You arent the brightest crayon in the box are you\",\n",
    "                          #\"I HOPE YOU GET THE SWINE FLU  WALLAH BRO  MOVE OUT OF UR MOMS BASEMENT\",\n",
    "                          #\"  I wasnt uncivil until you posted bullshit on my talk page at which point I told you to stop posting bullshit on my talk page  Bullshit BTW is when youre not lying and not telling the truth  you say what you think will get you what you want without any regard for the truth  ‚Äî   \",\n",
    "                          #\"Previous two dudes youre obviously closeminded dogmatists of Rationalism  You should honestly investigate claimed supernatural phenomena so you dont live bad lives and end up in Hell  Youre the irrational one by insisting without proper investigation that such phenomena is automatically bogus  And shame on the next dude for just parroting a false and malicious conclusion  You show forth your stupidity in the most abberant manner  I am a real scientist and I have examined what evidence is available to me regarding claims about Therese Neumann  She was a Saint and her phenomena proof of the truth of Catholicism which she herself indicates by her manner of life  Shes not an isolated case  Theres thousands of welldocumented and reliable accounts of modern and past supernatural phenomena on the part of Catholic Saints that backs up their claims that Jesus founded the Catholic Church and that its the only true religion  Everybody with wisdom realizes Wikipedia has a heavy liberal bias and wont give us the truth on almost anything  Giving both sides of the story here is not truth  Therese Neumann is one of thousands of messages from God to the world that it should be Catholic  And Neumann if the yogi dude isnt lying probably either didnt understand his words Eastern religious jargon or just wanted to be nice and not cause a fight  If he wanted her opinion in Western cultures you ask the person straightforward  Hinduisms are not at all like Catholicism  Hinduisms are more like I think I am one therefore I am  Catholics are Catholics only if they do and say what the Church defines that Catholics do  EG murderers commit a mortal sin and stop being Catholics  And Ill be honest with you guys like that would lie about what she said just to use her for their scheme  It seems more in line with what honest people record her saying that she told him hed go to Hell if he didnt become a Catholic      \",\n",
    "                          #\"vanmanh is a neeeeeeeeeeek\",\n",
    "                          #\"Bloodtraitor  You evil\",\n",
    "                          #\"yes and davie is a homosexual\"]\n",
    "\n",
    "# 12 (a dozen) comments which are expected to be nontoxic but were initially labeled toxic\n",
    "#expected_nontoxic_comments = [\"How dare you vandalize that page about the HMS Beagle Dont vandalize again demon\",\n",
    "                             #\"where I feel like a man instead of an idiot\",\n",
    "                             #\"The true truth is that only my balls have official status in the Principality of Monaco Stupid  Warm musky regards  His Most Serene Highness Prince Scruffy Musky Coinpurse IV\",\n",
    "                             #\"Thats helpful MOS be damned Thecodingproject thinks its 10x worse ‚Äî\",\n",
    "                             #\" Because the overall aim of the project is worth putting up with this for   Because there is sometimes some personal learning involved in the topic research which is itself a worthwhile goal   Otherwise no reason You can put up with the shit if you wish to its not usually too onerous Even the idiocy isnt too painful  youre only required to make the show of being civil to the fools not to respect them\",\n",
    "                             #\"Foolish nonsense I have never had to do something that stretched to the point of communicating with friends of friends to people on the other side of the earth Its quite pathetic actually and Calton is an inconsiderable selfish beast\",\n",
    "                             #\"Shut up please this consensus is over\",\n",
    "                             #\"  Utterly utterly tiny insignificant anal retentive thing but Its later learned that Dan Marino was about to be kidnap and join with Snowflake you missed a ped at the end of kidnap\",\n",
    "                             #\"And cybersex      \",\n",
    "                             #\"  someone please edit this line  The Lebanon Operation US Army Center for Military History Contingency Operations fckin stupid hoee  Its at the end of the article  TL\",\n",
    "                             #\"Thank you Ive done a bit more reading and it turns out that I in fact am an idiot but thank you for being nice about it\",\n",
    "                             #\"pls can you put a decent pic of him this one makes him look kind of stupid\"]\n",
    "\n",
    "#expected_toxic_comment_scores = []\n",
    "#expected_nontoxic_comment_scores = []\n",
    "\n",
    "#for c in expected_toxic_comments:\n",
    "    #analyze_request = {'comment': { 'text': c },'requestedAttributes': {'TOXICITY': {}}}\n",
    "    #response = client.comments().analyze(body=analyze_request).execute()\n",
    "    #print(json.dumps(response, indent=2))\n",
    "    #score = response[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"]\n",
    "    #expected_toxic_comment_scores.append(score)\n",
    "    \n",
    "#for c in expected_nontoxic_comments:\n",
    "    #analyze_request = {'comment': { 'text': c },'requestedAttributes': {'TOXICITY': {}}}\n",
    "    #response = client.comments().analyze(body=analyze_request).execute()\n",
    "    #print(json.dumps(response, indent=2))\n",
    "    #score = response[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"]\n",
    "    #expected_nontoxic_comment_scores.append(score)\n",
    "    \n",
    "#print(expected_toxic_comment_scores)\n",
    "#print(expected_nontoxic_comment_scores)\n",
    "\n",
    "#print(f\"Minimum and Maximum Toxicity Score of Sample Comments initially labeled nontoxic but were examined to be toxic: {min(expected_toxic_comment_scores)}, {max(expected_toxic_comment_scores)}\")\n",
    "\n",
    "#print(f\"Minimum and Maximum Toxicity Score of Sample Comments initially labeled toxic but were examined to be nontoxic: {min(expected_nontoxic_comment_scores)}, {max(expected_nontoxic_comment_scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5504e31",
   "metadata": {},
   "source": [
    "### Combining data and converting to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f409267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data to csv\n",
    "import pandas as pd\n",
    "data_tuples = list(zip(toxic_comments + nontoxic_comments, toxic_comment_scores + nontoxic_comment_scores))\n",
    "data_df = pd.DataFrame(data_tuples, columns=['Text','Toxicity Score'])\n",
    "\n",
    "data_df.to_csv(\"conversations_toxicity_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d05e4e9",
   "metadata": {},
   "source": [
    "### Analysis: Hypothesis\n",
    "\n",
    "My hypothesis is that the Perspective API will make more mistakes in assessing the toxicity of a long piece of text compared to a short piece of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b44b1a",
   "metadata": {},
   "source": [
    "### Analysis: Threshold\n",
    "\n",
    "From the results returned by the Perspective API, I have determined that an appropriate threshold for toxicity score to determine a comment to be toxic as 0.45, or 45% certainty. With my hypothesis being that shorter text will result in more mistakes than longer text, I will examine the comments which were incorrectly assessed and check their lengths to see if there is indeed any correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52798e2e",
   "metadata": {},
   "source": [
    "### Testing hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be2b3366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of toxic comment: 179\n",
      "Average length of comment incorrectly labeled toxic: 1208\n",
      "\n",
      "Average length of nontoxic comment: 192\n",
      "Average length of comment incorrectly labeled nontoxic: 203\n"
     ]
    }
   ],
   "source": [
    "# getting the incorrectly labeled toxic text's data, score, and length\n",
    "incorrectly_labeled_toxic = [\"  So on the tenth anniversary of 911 New York Times columnist Paul Krugman delivered the odious piece of dribble ever on the attack  well at least since the last time he wrote about it The headline is quote The Years of Shame end quote And no its not directed at radical Islam Instead he targets America and the quote fake heroes Krugman claims that the atrocity has been hijacked The sick word given that hes not actually talking about the real hijackers who killed some 3000 Americans No hes referring to people like George Bush and Rudy Giuliani who he thinks capitalized on the horrible crimes But the worst part at the end of this column the creep writes Im not going to allow comments on the post for obvious reasons That obvious reason hes a coward I mean why else would you ban responses Hes like a 10yearold boy crankcalling all of us only to hang up even before he hears a response hearing his shame for his own wickedness Now I watch the memorial services and I feel sorrow for the families whose grief never really ends But since Im lousy at emotional reflection I usually avoid it But at least I can summarize what many feel today in nine words go to hell Paul Krugman you bearded bitter buffoon\"]\n",
    "incorrectly_labeled_toxic_scores = [0.3561489]\n",
    "avg_len_incorrectly_labeled_toxic = len(incorrectly_labeled_toxic[0])\n",
    "\n",
    "# getting the avg length of toxic comments to compare with the length of the incorrectly labeled one\n",
    "avg_len_toxic = 0\n",
    "\n",
    "for c in toxic_comments:\n",
    "    avg_len_toxic += len(c)\n",
    "\n",
    "avg_len_toxic /= 12\n",
    "\n",
    "# getting the incorrectly labeled nontoxic text's data, score, and length\n",
    "incorrectly_labeled_nontoxic = [\"            Jews are not a race because you can only get it from your mother Your own mention of Ethiopian Jews not testing            as Jews proves it is not as well as the fact that we accept converts\"]\n",
    "incorrectly_labeled_nontoxic_scores = [0.4574824]\n",
    "avg_len_incorrectly_labeled_nontoxic = len(incorrectly_labeled_nontoxic[0])\n",
    "\n",
    "# getting the avg length of nontoxic comments to compare with the length of the incorrectly labeled one\n",
    "avg_len_nontoxic = 0\n",
    "\n",
    "for c in nontoxic_comments:\n",
    "    avg_len_nontoxic += len(c)\n",
    "\n",
    "avg_len_nontoxic /= 12\n",
    "\n",
    "print(f\"Average length of toxic comment: {round(avg_len_toxic)}\")\n",
    "print(f\"Average length of comment incorrectly labeled toxic: {avg_len_incorrectly_labeled_toxic}\")\n",
    "print()\n",
    "print(f\"Average length of nontoxic comment: {round(avg_len_nontoxic)}\")\n",
    "print(f\"Average length of comment incorrectly labeled nontoxic: {avg_len_incorrectly_labeled_nontoxic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a960753c",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "As we can wee, the average length of a toxic comment is 179 characters, and the comment which was incorrectly labeled as toxic had a much greater length of 1208. This supports our hypothesis that the Perspective API would be more likely to make mistakes on assessing the toxicity of a long piece of text rather than make a mistake in assessing the toxicity of a short piece of text. Additionally, we also looked at the average length of a nontoxic comment, which was 192, and the comment which was incorrectly labeled as nontoxic had length of 203, similar in length but about 5% longer. This also supports our hypothesis that the Perspective API would be more likely to make mistakes on assessing the toxicity of a long piece of text rather than make a mistake in assessing the toxicity of a short piece of text.\n",
    "\n",
    "A low sample size of 12 impacted our results by giving us few data points to work with. Mistakes in the first place seem to be relatively rare, as shown by finding only 1 mistake among the 12 data points and 2 among the 24 total data points. We can still begin to draw conclusions, but they should by no means be conclusive due to the low sample size. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cbdc6b",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b9419",
   "metadata": {},
   "source": [
    "Overall, I find this small project to be a very positive experience from which I learned a lot. I learned from the ground up how to use an API from Google Cloud and incorporate it in a project done from scratch. This involves getting the API, enabling it, figuring out how to use it (by getting an API key), and incorporating it into my code so that I can call it to perform it's various functions, in this case being a machine learning model which can score texts for toxicity. \n",
    "\n",
    "A surprising result I got was that the API does in fact seem more accurate with short texts than long texts, and I had initially thought that there are reasons to support either side of that argument. Short texts could be more innacurate because there might be less context that the API can derive in order to make it's decision, and it doesn't have many total words to work with. On the other hand, long texts give the API plenty of material to work with, but as we saw in our tests, long text is still able to \"trick\" the API into making an inaccuracy by potentially including lots of filler and carefully incorporating the insults and toxicity in more subtle ways. This could suggest that the model may draw its conclusions a bit too quickly, and may benefit from training with data that contains different punctionation types that elongate the sentence. \n",
    "\n",
    "To summarize, my hypothesis was that I thought the model would be more accurate with shorter text, and the bias that my tests suggested is in fact a bias towards shorter text, seeing that it was more accurate with shorter text than longer text. My theory for this bias is that there was less training data that included long text with punctations and  rarer grammatical forms, and thus the model became less accurate on this type of data and more accurate with short text data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
